# ğŸ™ï¸ GarsonAI - AI-Powered Voice Waiter System

**Ultra-low latency voice AI for restaurant ordering in Turkish**

[![FastAPI](https://img.shields.io/badge/FastAPI-0.115-green)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-19.2-blue)](https://reactjs.org/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## ğŸ“‹ Table of Contents

1. [Overview](#-overview)
2. [Key Features](#-key-features)
3. [Architecture](#-architecture)
4. [Tech Stack](#-tech-stack)
5. [Performance](#-performance)
6. [Installation](#-installation)
7. [Configuration](#%EF%B8%8F-configuration)
8. [Voice Pipeline Deep Dive](#-voice-pipeline-deep-dive)
9. [API Documentation](#-api-documentation)
10. [Database Schema](#-database-schema)
11. [Optimization Strategies](#-optimization-strategies)
12. [Development](#-development)
13. [Production Deployment](#-production-deployment)
14. [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ Overview

GarsonAI is a production-ready, real-time voice AI waiter system that enables restaurant customers to place orders using natural Turkish speech. The system leverages state-of-the-art AI models with aggressive latency optimization techniques to deliver a seamless conversational experience.

### What Makes GarsonAI Special?

- âš¡ **Full-duplex incremental STT**: 2.5-4s response (ideal), real-time transcription
- ğŸ¤ **Streaming pipeline**: Parallel processing (STT chunks â†’ LLM â†’ TTS overlap)
- ğŸ® **Manual control mode**: User-initiated recording, no auto-restart
- ğŸ‡¹ğŸ‡· **Turkish-native**: Optimized for Turkish language and restaurant context
- ğŸ“± **QR-based**: No app download, scan QR and start talking
- ğŸ”Š **Natural voices**: High-quality Turkish TTS (Zeynep voice, streaming)
- ğŸ›¡ï¸ **Production-ready**: JWT auth, retry logic, error resilience

---

## âœ¨ Key Features

### For Customers
- ğŸ—£ï¸ **Natural voice ordering in Turkish**
- ğŸ® **Manual control mode**: User-initiated recording (no auto-restart after AI)
- ğŸ“Š **Real-time incremental transcription**: See partial results while speaking
- ğŸ¯ **Smart silence detection**: 800ms VAD threshold for auto-stop
- ğŸ’¥ **Manual barge-in**: Interrupt AI responses on demand
- ğŸ”Š **Streaming AI responses**: Gapless audio playback
- ğŸ›’ **Manual menu browsing** and cart management
- ğŸ“± **QR code access** (no app needed)

### For Restaurant Owners
- ğŸ½ï¸ Menu management (CRUD operations)
- ğŸ“Š Real-time order tracking dashboard
- ğŸª‘ Table management with QR generation
- ğŸ“ˆ Order status updates (preparing/delivered/paid)
- ğŸ” Secure authentication (JWT)

### Technical Features
- ğŸš€ **Full-duplex incremental STT**: Process 500ms chunks in real-time
- âš¡ **Parallel pipeline**: LLM + TTS overlap processing
- ğŸ›¡ï¸ **STT resilience**: Rate limiting (500ms), retry logic (3x), chunk filtering
- ğŸ”„ **Connection pooling**: HTTP keep-alive for AI services
- ğŸŒ¡ï¸ **Container warmup**: Eliminates cold starts (2-3s â†’ 0s)
- ğŸ’¾ **Prompt caching**: Reduced LLM token usage
- ğŸ›ï¸ **uvloop event loop**: 2-4x faster async I/O
- ğŸ“¦ **Binary WebSocket**: Zero base64 overhead

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Customer (Mobile Browser)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ QR Scanner â”‚â”€â”€â”‚ Menu Browser â”‚â”€â”€â”‚ Voice AI Interface (â“¦) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ HTTP/WebSocket
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Backend (Python)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ REST API    â”‚  â”‚ WebSocket Hub â”‚  â”‚ Full-Duplex Voice      â”‚â”‚
â”‚  â”‚ (Auth/Menu) â”‚  â”‚ (Real-time)   â”‚  â”‚ Pipeline (Incremental  â”‚â”‚
â”‚  â”‚             â”‚  â”‚               â”‚  â”‚ STTâ†’LLMâ†’Parallel TTS)  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ SQL
                                 â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ PostgreSQL   â”‚
                        â”‚ (Restaurants,â”‚
                        â”‚ Tables, Menu,â”‚
                        â”‚ Orders)      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

External AI Services (via fal.ai & OpenRouter):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Freya STT    â”‚  â”‚ Gemini 2.5   â”‚  â”‚ Freya TTS    â”‚
â”‚ (Incremental)â”‚  |  Flash LLM   â”‚  â”‚ (Streaming)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Voice Pipeline Flow (Full-Duplex with Manual Control)

```
ğŸ¤ MANUAL CONTROL MODE:
User clicks "KonuÅŸmaya BaÅŸla" â†’ MediaRecorder starts (Opus 16kbps, Mono, 16kHz)
    â†“ (500ms chunks streaming, binary WebSocket)
    
ğŸ“Š INCREMENTAL STT (Real-time Processing):
Backend receives each 500ms chunk immediately
    â†“ (rate limited: min 500ms between requests)
    â†“ (chunk filter: skip if <1KB)
    â†“
Freya STT processes chunk â†’ Partial transcript
    â†“ (retry logic: 3x with exponential backoff on 500 errors)
    â†“
Send partial transcript to frontend â†’ Live display
    â†“ (continues for each chunk)
    
ğŸ›‘ VAD or Manual Stop:
800ms silence detected OR user clicks "Durdur"
    â†“
Final transcript sent to LLM
    â†“
    
ğŸ§  LLM Processing:
Gemini 2.5 Flash â†’ Streaming JSON Response
    â†“ (parallel pipeline: TTS starts immediately)
    
ğŸ”Š PARALLEL TTS:
Freya TTS (Zeynep) â†’ Streaming PCM16 Audio Chunks
    â†“ (WebSocket binary frames)
Frontend StreamingAudioPlayer â†’ Gapless Playback
    â†“
    
ğŸ”„ RETURN TO IDLE:
After TTS completes â†’ Mode: IDLE (NOT auto-recording)
User must click "KonuÅŸmaya BaÅŸla" again for next interaction

ğŸ’¥ BARGE-IN (Manual):
During AI speaking, user clicks "Kes / Yeniden KonuÅŸ"
    â†“ (interrupt signal â†’ cancel TTS streams)
    â†“
System returns to IDLE â†’ User clicks to restart
```

---

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework**: React 19.2 (with hooks)
- **Router**: React Router DOM 7.13
- **Styling**: TailwindCSS 4.1 + DaisyUI 5.5
- **Build Tool**: Vite 7.3
- **Audio**: Web Audio API (native)
- **WebSocket**: Native WebSocket API
- **QR**: qrcode.react 4.2

### Backend
- **Framework**: FastAPI 0.115 (async ASGI)
- **Server**: Uvicorn with uvloop (production-grade)
- **Database**: PostgreSQL + SQLAlchemy ORM
- **Auth**: JWT (python-jose + passlib)
- **WebSocket**: WebSockets library
- **AI Client**: fal-client (fal.ai SDK)
- **LLM**: OpenRouter (Google Gemini 2.5 Flash)

### AI Models
- **STT**: fal.ai Freya STT (TensorRT-optimized Whisper Large v3)
- **LLM**: Google Gemini 2.5 Flash (via OpenRouter)
- **TTS**: fal.ai Freya TTS (Turkish Zeynep voice, 16kHz PCM16 streaming)

---

## âš¡ Performance

### Latency Metrics (Full-Duplex Incremental Pipeline)

| Stage | Time | Details |
|-------|------|---------|
| **Audio Capture** | 0.0-2.5s | User speaks + 800ms VAD silence detection |
| **Incremental STT** | 0.5-1.5s | Per 500ms chunk (parallel with speaking) |
| **STT Retry (if error)** | 0-14s | Up to 3 retries with exponential backoff (2s, 4s, 8s) |
| **LLM First Token** | 0.2-0.4s | Gemini 2.5 Flash (streaming) |
| **TTS First Chunk** | 0.2-0.3s | Freya TTS (streaming PCM16, parallel with LLM) |
| **Audio Playback** | Immediate | Gapless Web Audio API streaming |
| **TOTAL (Ideal)** | **2.5-4.0s** | From speech end to audio start (no retries) âš¡ |
| **TOTAL (With Retries)** | **8-18s** | If STT API returns 500 errors (resilient but slower) |

**Note**: Actual latency depends on Freya STT API stability. In testing, first 1-2 interactions work smoothly (~3-4s), but persistent 500 errors may trigger retry logic adding 2-14s delay.

### Before vs After Optimization

```
BEFORE (Sequential Pipeline):
  Audio: 40KB stereo, 48kHz, 32kbps
  VAD: 1.5s silence threshold
  STT: Wait for full recording, then process
  Pipeline: Sequential (STT â†’ wait â†’ LLM â†’ wait â†’ TTS)
  Network: HTTP REST, blocking calls
  Total latency: 5-7 seconds

AFTER (Full-Duplex Incremental):
  Audio: 12-15KB mono, 16kHz, 16kbps  (-70% size!) âœ…
  VAD: 800ms silence threshold        (-700ms) âœ…
  STT: Incremental (process chunks while speaking) âš¡
  Pipeline: Parallel (LLM âˆ¥ TTS overlap) (-1-2s) âœ…
  Network: WebSocket binary, uvloop   (-300ms) âœ…
  Resilience: Retry logic + rate limiting (stability) âœ…
  Total latency: 2.5-4s ideal (50-60% faster!) ğŸš€
                 8-18s with retries (still completes reliably)
```

### Key Optimizations Applied
1. âœ… **Incremental STT**: Process 500ms chunks in real-time (not batch)
2. âœ… **Mono 16kHz audio**: 3x less data vs stereo 48kHz
3. âœ… **500ms chunk streaming**: Perceived latency < 500ms
4. âœ… **Aggressive VAD (800ms)**: 700ms faster auto-stop
5. âœ… **Binary WebSocket**: No base64 overhead (-33%)
6. âœ… **uvloop event loop**: 2-4x faster async I/O
7. âœ… **Parallel pipeline**: TTS starts while LLM streams
8. âœ… **STT resilience**: Rate limiting (500ms min) + retry (3x exponential backoff)
9. âœ… **Chunk filtering**: Skip audio < 1KB (avoid empty chunks)
10. âœ… **Manual control mode**: User-initiated recording (better UX)

---

## ğŸš€ Installation

### Prerequisites
- Python 3.10+
- Node.js 18+
- PostgreSQL 14+
- fal.ai API key ([get one here](https://fal.ai))
- OpenRouter API key ([get one here](https://openrouter.ai))

### Quick Start

#### 1. Clone Repository
```bash
git clone https://github.com/yourusername/fal-freya-garsonai.git
cd fal-freya-garsonai
```

#### 2. Backend Setup
```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies (includes uvloop for performance)
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys and database URL
```

#### 3. Frontend Setup
```bash
cd ../frontend

# Install dependencies
npm install

# Configure API endpoint (if needed)
# Edit src/services/api.js to point to your backend
```

#### 4. Database Setup
```bash
# Create PostgreSQL database
createdb garsonai

# Update DATABASE_URL in backend/.env
DATABASE_URL=postgresql://user:password@localhost/garsonai

# Tables will be auto-created on first run (SQLAlchemy)
```

#### 5. Run Application

**Option 1: Optimized Start Script (Recommended)**
```bash
# From project root
chmod +x start-optimized.sh
./start-optimized.sh
```

**Option 2: Manual Start**
```bash
# Terminal 1: Backend with uvloop
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000 --loop uvloop --ws websockets

# Terminal 2: Frontend
cd frontend
npm run dev
```

#### 6. Access Application
- **Frontend**: http://localhost:5173
- **Backend API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs (Swagger UI)

---

## âš™ï¸ Configuration

### Backend Environment Variables

Create `backend/.env` with:

```bash
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/garsonai

# Security
SECRET_KEY=your-super-secret-jwt-key-change-this-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=43200  # 30 days

# AI Services
FAL_KEY=your-fal-api-key-here
OPENROUTER_API_KEY=your-openrouter-api-key-here

# Optional: Model overrides
# STT_MODEL=freya-mypsdi253hbk/freya-stt/generate
# TTS_MODEL=freya-mypsdi253hbk/freya-tts/generate
# LLM_MODEL=google/gemini-2.5-flash
```

### Frontend Configuration

Edit `frontend/src/services/api.js` if backend URL differs:

```javascript
const API_BASE_URL = import.meta.env.VITE_API_URL || 'http://localhost:8000';
const WS_BASE_URL = import.meta.env.VITE_WS_URL || 'ws://localhost:8000';
```

### Voice Pipeline Tuning

Adjust in `frontend/src/pages/VoiceAI.jsx`:

```javascript
// VAD sensitivity (800ms = aggressive, 1500ms = conservative)
silenceDuration: 800

// Audio quality (lower = smaller file, faster upload)
audioBitsPerSecond: 16000  // 16kbps for voice

// Chunk size (500ms = real-time feedback)
mediaRecorder.start(500)
```

---

## ğŸ¤ Voice Pipeline Deep Dive

### Complete Flow Diagram

````
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: AUDIO CAPTURE (Frontend - Manual Control Mode)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ 1. ğŸ® User clicks "KonuÅŸmaya BaÅŸla" button (Manual Start)        â”‚
â”‚    - System does NOT auto-start after AI response                 â”‚
â”‚    - User has full control of when to speak                       â”‚
â”‚                                                                     â”‚
â”‚ 2. ğŸ¤ Request microphone permission (if not granted)              â”‚
â”‚    getUserMedia({audio: {channelCount: 1, sampleRate: 16000}})   â”‚
â”‚                                                                     â”‚
â”‚ 3. ğŸ“¼ MediaRecorder with Opus codec:                              â”‚
â”‚    - Container: WebM                                               â”‚
â”‚    - Codec: Opus (voice-optimized)                                â”‚
â”‚    - Bitrate: 16kbps (low latency)                                â”‚
â”‚    - Channels: Mono (1 channel)                                   â”‚
â”‚    - Sample Rate: 16kHz (STT native)                              â”‚
â”‚                                                                     â”‚
â”‚ 4. â–¶ï¸ Start recording in 500ms chunks:                            â”‚
â”‚    mediaRecorder.start(500)                                       â”‚
â”‚    - Each chunk sent immediately via WebSocket                    â”‚
â”‚    - Incremental STT processing begins                            â”‚
â”‚                                                                     â”‚
â”‚ 5. ğŸ›‘ Stop Options:                                               â”‚
â”‚    a) VAD Auto-stop: 800ms silence detected                       â”‚
â”‚    b) Manual stop: User clicks "Durdur" button                    â”‚
â”‚    c) Manual interrupt: User clicks "Kes / Yeniden KonuÅŸ"        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: VOICE ACTIVITY DETECTION (Frontend)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ VoiceActivityDetector.js - Runs every 100ms:                      â”‚
â”‚                                                                     â”‚
â”‚ 1. Get time-domain audio data (waveform)                          â”‚
â”‚    analyser.getByteTimeDomainData(dataArray)                      â”‚
â”‚                                                                     â”‚
â”‚ 2. Calculate RMS (Root Mean Square) amplitude:                    â”‚
â”‚    rms = sqrt(Î£(sampleÂ²) / length)                                â”‚
â”‚                                                                     â”‚
â”‚ 3. Check silence threshold (0.01 = 1% amplitude):                 â”‚
â”‚    if (rms < 0.01) {                                              â”‚
â”‚      silenceDuration += 100ms                                     â”‚
â”‚      if (silenceDuration >= 800ms) {                              â”‚
â”‚        trigger AUTO-STOP                                          â”‚
â”‚      }                                                             â”‚
â”‚    } else {                                                        â”‚
â”‚      silenceDuration = 0  // Reset on voice activity             â”‚
â”‚    }                                                               â”‚
â”‚                                                                     â”‚
â”‚ Result: Recording stops 800ms after user finishes speaking        â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3: AUDIO STREAMING (Frontend â†’ Backend, Incremental)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ WebSocket Binary Streaming (Real-time):                            â”‚
â”‚                                                                     â”‚
â”‚ 1. ğŸ“¤ mediaRecorder.ondataavailable (fires every 500ms):          â”‚
â”‚    - Get audio chunk (Blob ~1-2KB)                                â”‚
â”‚    - Convert to ArrayBuffer: await chunk.arrayBuffer()            â”‚
â”‚    - Send via WebSocket binary: ws.send(arrayBuffer)              â”‚
â”‚    - Backend receives immediately                                 â”‚
â”‚    - âš¡ INCREMENTAL STT starts on this chunk (parallel)          â”‚
â”‚                                                                     â”‚
â”‚ 2. ğŸ” Repeat for each 500ms chunk:                                â”‚
â”‚    - User keeps speaking â†’ chunks keep streaming                  â”‚
â”‚    - Backend processes each chunk independently                   â”‚
â”‚    - Partial transcripts sent back in real-time                   â”‚
â”‚    - Frontend displays live updates                               â”‚
â”‚                                                                     â”‚
â”‚ 3. ğŸ›‘ On stop (VAD triggered or manual "Durdur"):                â”‚
â”‚    - Send audio_end signal:                                       â”‚
â”‚      ws.send(JSON.stringify({type: "audio_end"}))                â”‚
â”‚    - Backend uses last full transcript for LLM                    â”‚
â”‚    - No "combining" - already processed incrementally             â”‚
â”‚                                                                     â”‚
â”‚ Advantages:                                                         â”‚
â”‚ âœ… Real-time transcript display (user sees text while speaking)   â”‚
â”‚ âœ… Instant UI feedback ("receiving" status)                       â”‚
â”‚ âœ… No large single upload wait                                    â”‚
â”‚ âœ… Binary frames (no base64 overhead)                             â”‚
â”‚ âœ… Perceived latency near-zero                                    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 4: INCREMENTAL SPEECH-TO-TEXT (Backend)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ PartialSTTService (backend/services/partial_stt.py):              â”‚
â”‚                                                                     â”‚
â”‚ ğŸ”„ REAL-TIME INCREMENTAL PROCESSING:                              â”‚
â”‚                                                                     â”‚
â”‚ For EACH 500ms audio chunk received:                              â”‚
â”‚                                                                     â”‚
â”‚ 1. â±ï¸ RATE LIMITING (Anti-throttle):                              â”‚
â”‚    - Check: time_since_last_request < 500ms?                      â”‚
â”‚    - If yes: await asyncio.sleep(500ms - elapsed)                 â”‚
â”‚    - Purpose: Prevent API rate limit 429 errors                   â”‚
â”‚                                                                     â”‚
â”‚ 2. ğŸ“ CHUNK FILTERING (Quality control):                          â”‚
â”‚    - Check: len(audio_data) < 1000 bytes?                         â”‚
â”‚    - If yes: Skip (too small, likely silence)                     â”‚
â”‚    - Purpose: Avoid wasting API calls on empty chunks             â”‚
â”‚                                                                     â”‚
â”‚ 3. ğŸ“¤ UPLOAD TO CDN:                                              â”‚
â”‚    - Save chunk to temp file (WebM/Opus format)                   â”‚
â”‚    - Upload via fal_client.upload_file()                          â”‚
â”‚    - Get CDN URL (required by Freya STT API)                      â”‚
â”‚                                                                     â”‚
â”‚ 4. ğŸ™ï¸ STT API CALL with RETRY LOGIC:                            â”‚
â”‚    for attempt in range(3):  # Max 3 retries                      â”‚
â”‚      try:                                                          â”‚
â”‚        result = fal_client.subscribe(                              â”‚
â”‚          "freya-mypsdi253hbk/freya-stt/generate",                 â”‚
â”‚          arguments={                                               â”‚
â”‚            "audio_url": cdn_url,                                  â”‚
â”‚            "task": "transcribe",                                  â”‚
â”‚            "language": "tr",                                      â”‚
â”‚            "chunk_level": "segment"                               â”‚
â”‚          }                                                         â”‚
â”‚        )                                                           â”‚
â”‚        break  # Success!                                          â”‚
â”‚      except 500 InternalServerError:                              â”‚
â”‚        if attempt < 2:                                            â”‚
â”‚          wait_time = 2 ** attempt * 2  # 2s, 4s, 8s              â”‚
â”‚          await asyncio.sleep(wait_time)                           â”‚
â”‚        else:                                                       â”‚
â”‚          raise  # Give up after 3 attempts                        â”‚
â”‚                                                                     â”‚
â”‚ 5. âœ… RETURN PARTIAL TRANSCRIPT:                                 â”‚
â”‚    - Extract text from result["text"]                             â”‚
â”‚    - Send to frontend via WebSocket                               â”‚
â”‚    - Frontend displays live (e.g., "Merhaba ben..." â†’ "Merhaba   â”‚
â”‚      ben bir yiyecek...")                                         â”‚
â”‚                                                                     â”‚
â”‚ 6. ğŸ” REPEAT for next chunk (until VAD stop or manual stop)      â”‚
â”‚                                                                     â”‚
â”‚ ADVANTAGES:                                                         â”‚
â”‚ âœ… User sees transcript in real-time (not after recording ends)   â”‚
â”‚ âœ… Faster perceived latency (first words appear in 0.5-1s)        â”‚
â”‚ âœ… Resilient to API failures (retry logic + rate limiting)        â”‚
â”‚ âœ… Efficient (skip tiny/silent chunks)                            â”‚
â”‚                                                                     â”‚
â”‚ NOTE: On VAD silence or manual stop, final transcript is sent to  â”‚
â”‚ LLM for processing (not accumulated from partials, but last full  â”‚
â”‚ transcription).                                                     â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 5: NATURAL LANGUAGE UNDERSTANDING (Backend)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ LLMService (backend/services/llm.py):                             â”‚
â”‚                                                                     â”‚
â”‚ Ultra-compact prompt (~50 tokens):                                 â”‚
â”‚                                                                     â”‚
â”‚ ```                                                                 â”‚
â”‚ GarsonAI bot. KÄ±sa yanÄ±t (max 10 kelime).                         â”‚
â”‚ JSON only:                                                          â”‚
â”‚ {                                                                   â”‚
â”‚   "spoken_response": "...",                                        â”‚
â”‚   "intent": "add|info|greet|other",                               â”‚
â”‚   "product_name": "...",                                           â”‚
â”‚   "quantity": 1                                                     â”‚
â”‚ }                                                                   â”‚
â”‚                                                                     â”‚
â”‚ MenÃ¼:                                                               â”‚
â”‚ - Pizza: 150TL (Klasik Ä°talyan)                                   â”‚
â”‚ - Kola: 25TL (330ml soÄŸuk iÃ§ecek)                                 â”‚
â”‚                                                                     â”‚
â”‚ MÃ¼ÅŸteri: "Ä°ki pizza ve bir kola lÃ¼tfen"                          â”‚
â”‚ ```                                                                 â”‚
â”‚                                                                     â”‚
â”‚ Streaming Response:                                                 â”‚
â”‚ 1. Call Gemini 2.5 Flash via OpenRouter                           â”‚
â”‚ 2. Stream tokens in real-time (yield each chunk)                  â”‚
â”‚ 3. Frontend receives token-by-token updates                        â”‚
â”‚ 4. Full JSON response built incrementally                          â”‚
â”‚                                                                     â”‚
â”‚ Parallel TTS Trigger:                                               â”‚
â”‚ - Regex detects first complete sentence: [.!?]                    â”‚
â”‚ - Extract "spoken_response" field from JSON                        â”‚
â”‚ - Start TTS in parallel (asyncio.create_task)                     â”‚
â”‚ - LLM continues streaming while TTS runs                           â”‚
â”‚                                                                     â”‚
â”‚ Result: TTS latency hidden by LLM completion                       â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 6: TEXT-TO-SPEECH (Backend)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ TTSService (backend/services/tts.py):                             â”‚
â”‚                                                                     â”‚
â”‚ Streaming TTS (Real-time):                                         â”‚
â”‚                                                                     â”‚
â”‚ 1. Input: "Tabii, iki pizza ve bir kola ekliyorum!"              â”‚
â”‚ 2. Call Freya TTS /stream endpoint:                               â”‚
â”‚    - Voice: "zeynep" (Turkish female)                             â”‚
â”‚    - Format: PCM16 (16kHz, mono)                                  â”‚
â”‚    - Speed: 1.15x (slightly faster)                               â”‚
â”‚    - Streaming: True (chunks arrive in real-time)                 â”‚
â”‚                                                                     â”‚
â”‚ 3. Receive base64-encoded PCM16 chunks:                           â”‚
â”‚    for event in fal_client.stream(...):                           â”‚
â”‚      if "audio" in event:                                         â”‚
â”‚        pcm_bytes = base64.b64decode(event["audio"])               â”‚
â”‚        yield pcm_bytes  # Send immediately via WebSocket          â”‚
â”‚                                                                     â”‚
â”‚ 4. First chunk arrives in 0.2-0.3s (vs 3s for full audio)        â”‚
â”‚ 5. Total chunks: ~15-20 for typical response                      â”‚
â”‚ 6. Chunk size: 2-4KB PCM16 data each                              â”‚
â”‚                                                                     â”‚
â”‚ Optimization: Warmup container (30s interval)                      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 7: AUDIO PLAYBACK (Frontend)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ StreamingAudioPlayer.js:                                           â”‚
â”‚                                                                     â”‚
â”‚ Gapless Real-time Playback:                                        â”‚
â”‚                                                                     â”‚
â”‚ 1. WebSocket receives binary PCM16 chunk                           â”‚
â”‚ 2. Convert PCM16 â†’ AudioBuffer:                                   â”‚
â”‚    - Read Int16Array from bytes                                   â”‚
â”‚    - Normalize to Float32: sample / 32768.0                       â”‚
â”‚    - Create mono 16kHz AudioBuffer                                â”‚
â”‚                                                                     â”‚
â”‚ 3. Schedule playback (Web Audio API):                             â”‚
â”‚    const source = audioContext.createBufferSource()               â”‚
â”‚    source.buffer = audioBuffer                                    â”‚
â”‚    source.connect(audioContext.destination)                       â”‚
â”‚    source.start(scheduledTime)  // Precise timing for gapless    â”‚
â”‚                                                                     â”‚
â”‚ 4. Queue management:                                               â”‚
â”‚    - First chunk: Start immediately (this.currentTime = now)     â”‚
â”‚    - Subsequent chunks: Schedule after previous                   â”‚
â”‚    - scheduledTime += audioBuffer.duration                        â”‚
â”‚    - Result: Seamless audio stream (no gaps/stutters)            â”‚
â”‚                                                                     â”‚
â”‚ 5. User hears audio while TTS is still streaming chunks!          â”‚
â”‚                                                                     â”‚
â”‚ Final Result: Perceived latency ~1.8-2.2s from speech end         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

### Timing Example (Incremental STT Pipeline - Ideal Case)

```
[00:00.000] ğŸ¤ User clicks "KonuÅŸmaya BaÅŸla" button
[00:00.050] ğŸ™ï¸ MediaRecorder starts (Mono, 16kHz, Opus 16kbps)
[00:00.500] ğŸ“¤ First 500ms chunk sent â†’ STT processing starts
[00:01.200] ğŸ“ First partial transcript: "Ä°ki" (displayed live)
[00:01.500] ğŸ“¤ Second 500ms chunk sent
[00:02.100] ğŸ“ Second partial: "Ä°ki pizza" (updated live)
[00:02.500] ğŸ“¤ Third 500ms chunk sent
[00:03.000] ğŸ“ Third partial: "Ä°ki pizza lÃ¼tfen" (updated live)
[00:03.300] ğŸ›‘ User stops speaking (silence detected)
[00:04.100] â¹ï¸ VAD threshold (800ms) â†’ Auto-stop recording
[00:04.150] âœ… Final transcript confirmed: "Ä°ki pizza lÃ¼tfen"
[00:04.200] ğŸ§  LLM starts (Gemini 2.5 Flash)
[00:04.400] âš¡ LLM first token received (200ms)
[00:04.450] ğŸ“ First sentence complete: "Tabii, iki pizza ekliyorum!"
[00:04.450] ğŸ”Š Parallel TTS task created (asyncio.create_task)
[00:04.650] ğŸµ TTS first chunk received (200ms from TTS start) âš¡
[00:04.670] ğŸ”Š Frontend plays first audio chunk â†’ USER HEARS! ğŸ§
[00:05.500] âœ… LLM complete (1.3s total)
[00:06.100] âœ… TTS complete (1.65s total, playback started at 4.67s)
[00:06.850] ğŸµ Audio playback complete
[00:06.850] ğŸ”„ System returns to IDLE (user must click to speak again)

ğŸ’¡ TOTAL PERCEIVED LATENCY: 4.670s - 4.100s = 0.57 seconds âš¡âš¡âš¡
   (From recording stop to first audio playback)

ğŸ“Š USER EXPERIENCE:
   - Saw live transcript while speaking (0.5-3.0s)
   - AI response started playing in <1s after finishing
   - Manual control: User decides when to speak again
```

### Timing Example (With STT Retry - Worst Case)

```
[00:00.000] ğŸ¤ User starts speaking
[00:00.500] ğŸ“¤ First chunk sent
[00:01.000] âŒ STT API 500 error (attempt 1/3)
[00:03.000] ğŸ”„ Retry after 2s
[00:03.500] âŒ STT API 500 error (attempt 2/3)
[00:07.500] ğŸ”„ Retry after 4s
[00:08.000] âœ… STT success (attempt 3/3)
[00:08.100] ğŸ“ Partial transcript displayed
... (continues as above)

ğŸ’¡ TOTAL LATENCY WITH RETRIES: ~12-15 seconds
   (Resilient but slower due to API instability)

ğŸ›¡ï¸ RESILIENCE FEATURES:
   - Rate limiting: Min 500ms between requests
   - Retry logic: 3 attempts with exponential backoff (2s, 4s, 8s)
   - Chunk filtering: Skip empty chunks (<1KB)
   - Turkish error messages: User-friendly feedback
```

---

## ğŸ“š API Documentation

### Authentication Endpoints

#### POST `/api/auth/register`
Register new restaurant account.

**Request:**
```json
{
  "name": "Restaurant Name",
  "email": "owner@restaurant.com",
  "password": "securepassword123"
}
```

**Response:**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

#### POST `/api/auth/login`
Login to existing account.

**Request:**
```json
{
  "username": "owner@restaurant.com",
  "password": "securepassword123"
}
```

**Response:**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer"
}
```

---

### Restaurant Management (Protected)

**Authentication Required:** All endpoints require `Authorization: Bearer <token>` header.

#### GET `/api/restaurant/tables`
Get all tables for authenticated restaurant.

**Response:**
```json
[
  {
    "id": 1,
    "table_number": 5,
    "qr_token": "abc123def456",
    "is_active": true,
    "qr_link": "http://localhost:5173/menu/abc123def456"
  }
]
```

#### POST `/api/restaurant/tables`
Create new table with QR code.

**Request:**
```json
{
  "table_number": 10
}
```

**Response:**
```json
{
  "id": 2,
  "table_number": 10,
  "qr_token": "xyz789uvw012",
  "is_active": true,
  "qr_link": "http://localhost:5173/menu/xyz789uvw012"
}
```

#### DELETE `/api/restaurant/tables/{table_id}`
Delete table.

**Response:**
```json
{
  "message": "Table deleted"
}
```

#### GET `/api/restaurant/orders`
Get all orders for restaurant. Query parameters: `?status=preparing`

**Response:**
```json
[
  {
    "id": 1,
    "table": {"table_number": 5},
    "status": "preparing",
    "total_price": 175.0,
    "items": [
      {
        "product": {"name": "Pizza", "price": 150.0},
        "quantity": 1
      },
      {
        "product": {"name": "Kola", "price": 25.0},
        "quantity": 1
      }
    ],
    "created_at": "2026-02-12T14:30:00"
  }
]
```

#### PATCH `/api/restaurant/orders/{order_id}/status`
Update order status.

**Request:**
```json
{
  "status": "delivered"
}
```

**Response:**
```json
{
  "id": 1,
  "status": "delivered"
}
```

---

### Menu Management (Protected)

#### GET `/api/menu/products`
Get all products for authenticated restaurant.

#### POST `/api/menu/products`
Create new menu item.

**Request:**
```json
{
  "name": "Pizza Margherita",
  "description": "Klasik Ä°talyan pizza",
  "price": 150.0,
  "category": "Ana Yemek",
  "image_url": "https://example.com/pizza.jpg",
  "is_available": true
}
```

#### PATCH `/api/menu/products/{product_id}`
Update menu item.

#### DELETE `/api/menu/products/{product_id}`
Delete menu item.

---

### Public Menu Endpoints

#### GET `/api/menu/{qr_token}`
Get menu for specific table (public access).

**Response:**
```json
{
  "restaurant": {
    "id": 1,
    "name": "Restaurant Name"
  },
  "table": {
    "id": 1,
    "table_number": 5
  },
  "products": [
    {
      "id": 1,
      "name": "Pizza",
      "description": "Lezzetli pizza",
      "price": 150.0,
      "category": "Ana Yemek",
      "is_available": true
    }
  ]
}
```

#### POST `/api/menu/{qr_token}/checkout`
Place order (manual or voice-generated).

**Request:**
```json
{
  "items": [
    {"product_id": 1, "quantity": 2},
    {"product_id": 3, "quantity": 1}
  ]
}
```

**Response:**
```json
{
  "order_id": 42,
  "total_price": 325.0,
  "status": "preparing",
  "message": "SipariÅŸiniz alÄ±ndÄ±!"
}
```

---

### WebSocket Voice Endpoint

#### WS `/ws/voice/{qr_token}`
Real-time voice AI pipeline.

**Connection:**
```javascript
const ws = new WebSocket('ws://localhost:8000/ws/voice/abc123def456');
```

**Client â†’ Server Messages:**

1. **Audio chunks (binary):**
```javascript
ws.send(audioBlob);  // 500ms WebM/Opus chunks
```

2. **Control messages (JSON):**
```javascript
// Signal end of recording
ws.send(JSON.stringify({type: "audio_end"}));

// Keep-alive ping
ws.send(JSON.stringify({type: "ping"}));
```

**Server â†’ Client Messages:**

1. **Status updates:**
```json
{"type": "status", "message": "receiving"}
{"type": "status", "message": "processing"}
```

2. **Transcript:**
```json
{"type": "transcript", "text": "Ä°ki pizza lÃ¼tfen"}
```

3. **AI streaming tokens:**
```json
{
  "type": "ai_token",
  "token": "Tabii",
  "full_text": "Tabii, iki pizza ekliyorum!"
}
```

4. **AI complete:**
```json
{
  "type": "ai_complete",
  "data": {
    "spoken_response": "Tabii, iki pizza ekliyorum!",
    "intent": "add",
    "product_name": "Pizza",
    "quantity": 2
  }
}
```

5. **TTS events:**
```json
{"type": "tts_start"}
{"type": "tts_complete"}
```

6. **Audio chunks (binary):**
```javascript
// Blob containing PCM16 audio data
event.data // instanceof Blob
```

7. **Errors:**
```json
{"type": "error", "message": "STT service unavailable"}
```

---

## ğŸ—„ï¸ Database Schema

### Entity Relationship Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  restaurants    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚â†â”€â”€â”
â”‚ name            â”‚   â”‚
â”‚ email (unique)  â”‚   â”‚
â”‚ hashed_password â”‚   â”‚
â”‚ created_at      â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                       â”‚ (1:N)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     tables      â”‚   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚ id (PK)         â”‚   â”‚
â”‚ restaurant_id â”€â”€â”¼â”€â”€â”€â”˜
â”‚ table_number    â”‚
â”‚ qr_token (uniq) â”‚â†â”€â”€â”
â”‚ is_active       â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                       â”‚ (1:N)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚    products     â”‚   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚ id (PK)         â”‚   â”‚
â”‚ restaurant_id â”€â”€â”¼â”€â”€â”€â”¤
â”‚ name            â”‚   â”‚
â”‚ description     â”‚   â”‚
â”‚ price           â”‚   â”‚
â”‚ category        â”‚   â”‚
â”‚ image_url       â”‚   â”‚
â”‚ is_available    â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     orders      â”‚   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚ id (PK)         â”‚   â”‚
â”‚ restaurant_id â”€â”€â”¼â”€â”€â”€â”¤
â”‚ table_id â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”˜
â”‚ status          â”‚
â”‚ total_price     â”‚
â”‚ created_at      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ (1:N)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  order_items    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚
â”‚ order_id (FK)   â”‚
â”‚ product_id (FK) â”‚
â”‚ quantity        â”‚
â”‚ price           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SQL Schema

```sql
-- Restaurants
CREATE TABLE restaurants (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    hashed_password VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Tables
CREATE TABLE tables (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER REFERENCES restaurants(id) ON DELETE CASCADE,
    table_number INTEGER NOT NULL,
    qr_token VARCHAR(255) UNIQUE NOT NULL,
    is_active BOOLEAN DEFAULT TRUE
);

-- Products (Menu Items)
CREATE TABLE products (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER REFERENCES restaurants(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    price NUMERIC(10, 2) NOT NULL,
    category VARCHAR(100),
    image_url VARCHAR(500),
    is_available BOOLEAN DEFAULT TRUE
);

-- Orders
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    restaurant_id INTEGER REFERENCES restaurants(id) ON DELETE CASCADE,
    table_id INTEGER REFERENCES tables(id) ON DELETE SET NULL,
    status VARCHAR(50) DEFAULT 'preparing',  -- preparing/delivered/paid
    total_price NUMERIC(10, 2) NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Order Items
CREATE TABLE order_items (
    id SERIAL PRIMARY KEY,
    order_id INTEGER REFERENCES orders(id) ON DELETE CASCADE,
    product_id INTEGER REFERENCES products(id) ON DELETE SET NULL,
    quantity INTEGER NOT NULL,
    price NUMERIC(10, 2) NOT NULL
);

-- Indexes for performance
CREATE INDEX idx_tables_qr_token ON tables(qr_token);
CREATE INDEX idx_tables_restaurant_id ON tables(restaurant_id);
CREATE INDEX idx_products_restaurant_id ON products(restaurant_id);
CREATE INDEX idx_orders_restaurant_id ON orders(restaurant_id);
CREATE INDEX idx_orders_status ON orders(status);
CREATE INDEX idx_order_items_order_id ON order_items(order_id);
```

---

## ğŸ”§ Optimization Strategies

### Audio Optimization

#### 1. Mono Audio (50% reduction)
**Problem:** Stereo captures 2 channels but voice is mono.  
**Solution:** Request mono via `channelCount: 1` in getUserMedia.  
**Impact:** 50% less data to upload and process.

```javascript
// frontend/src/pages/VoiceAI.jsx
const stream = await navigator.mediaDevices.getUserMedia({ 
  audio: {
    channelCount: 1,  // Mono instead of stereo
    echoCancellation: true,
    noiseSuppression: true
  } 
});
```

#### 2. 16kHz Sample Rate (66% reduction)
**Problem:** Default 48kHz captures more data than needed for speech.  
**Solution:** Request 16kHz (Whisper's native sample rate).  
**Impact:** 3x less data, faster upload, same quality.

```javascript
audio: {
  sampleRate: 16000  // Whisper processes at 16kHz internally
}
```

#### 3. 16kbps Opus Codec (voice-optimized)
**Problem:** Default bitrate (32kbps) over-compresses or wastes bandwidth.  
**Solution:** 16kbps Opus is perfect for voice.  
**Impact:** Smaller files, faster inference.

```javascript
const mediaRecorder = new MediaRecorder(stream, {
  mimeType: "audio/webm;codecs=opus",
  audioBitsPerSecond: 16000  // Optimized for speech
});
```

**Combined Result:** 40KB â†’ 12-15KB audio files (-70%)

---

### Latency Optimization

#### 4. Chunk Streaming (perceived latency < 50ms)
**Problem:** Wait for full recording before processing.  
**Solution:** Stream 500ms chunks in real-time.  
**Impact:** Instant UI feedback, user knows system is responding.

```javascript
mediaRecorder.start(500);  // 500ms chunks

mediaRecorder.ondataavailable = (event) => {
  ws.send(event.data);  // Send immediately
  console.log("ğŸ“¤ Chunk sent");
};
```

#### 5. Aggressive VAD (700ms saved)
**Problem:** 1.5s silence wait feels slow.  
**Solution:** 800ms threshold is sweet spot (natural pauses < 800ms).  
**Impact:** Recording stops 700ms faster.

```javascript
// frontend/src/utils/VoiceActivityDetector.js
constructor(options = {}) {
  this.silenceThreshold = 0.01;  // 1% amplitude
  this.silenceDuration = 800;     // 800ms silence = stop
}
```

#### 6. Binary WebSocket (no base64 overhead)
**Problem:** Base64 encoding adds 33% size overhead.  
**Solution:** Send audio as binary WebSocket frames.  
**Impact:** Smaller payload, faster transmission.

```javascript
// Send binary directly
ws.send(audioBlob);  // No encoding needed

// Backend receives
data = await websocket.receive()
audio_chunk = data["bytes"]  // Raw bytes
```

#### 7. uvloop Event Loop (2-4x faster async)
**Problem:** Python's default asyncio is CPU-bound.  
**Solution:** uvloop uses libuv (same as Node.js).  
**Impact:** 100-250ms faster I/O operations.

```bash
# Start server with uvloop
uvicorn main:app --loop uvloop --ws websockets
```

```python
# backend/requirements.txt
uvloop
```

#### 8. Container Warmup (eliminates cold starts)
**Problem:** First TTS request takes 2-3s (container startup).  
**Solution:** Background task sends dummy request every 30s.  
**Impact:** All requests fast (0.4-0.9s).

```python
# backend/services/tts_warmer.py
def warmup_tts():
    while running:
        try:
            fal_client.subscribe(TTS_MODEL, arguments={"input": "test"})
        except:
            pass
        time.sleep(30)  # Keep warm

# backend/main.py
@asynccontextmanager
async def lifespan(app: FastAPI):
    start_tts_warmer(interval=30)
    yield
    stop_tts_warmer()
```

#### 9. Parallel Pipeline (600ms hidden latency)
**Problem:** Sequential STT â†’ LLM â†’ TTS wastes time.  
**Solution:** Start TTS when first LLM sentence completes.  
**Impact:** TTS runs while LLM finishes, 600ms saved.

```python
# backend/routers/voice_routes.py
async for llm_event in llm_service.generate_stream(...):
    if first_sentence_complete:
        # Start TTS in background while LLM continues
        tts_task = asyncio.create_task(stream_tts_parallel())
```

#### 10. Streaming TTS (2.3s faster first audio)
**Problem:** Wait for full MP3 generation (3.1s).  
**Solution:** Stream PCM16 chunks in real-time.  
**Impact:** First audio in 0.23s (was 3.1s).

```python
# backend/services/tts.py
stream = fal_client.stream(TTS_MODEL, path="/stream")
for event in stream:
    if "audio" in event:
        pcm_chunk = base64.b64decode(event["audio"])
        yield pcm_chunk  # Send immediately!
```

```javascript
// frontend/src/utils/StreamingAudioPlayer.js
async addPCMChunk(pcmBytes) {
  const audioBuffer = await this.pcmToAudioBuffer(pcmBytes);
  this.playNext();  // Play immediately, no buffering!
}
```

---

### Prompt Optimization

#### 11. Minimal Prompt Tokens (~50 tokens)
**Problem:** Long prompts increase LLM latency and cost.  
**Solution:** Ultra-compact system prompt.  
**Impact:** 200-400ms faster LLM response.

```python
# backend/services/llm.py - BEFORE (125 tokens)
prompt = f"""
You are GarsonAI, a helpful restaurant voice assistant...
[long instructions]
Menu: {menu_context}
Customer: {transcript}
"""

# AFTER (50 tokens) âœ…
prompt = f"""GarsonAI bot. KÄ±sa yanÄ±t (max 10 kelime).
JSON only: {{"spoken_response":"...","intent":"add|info|hi","product_name":"...","quantity":1}}
MenÃ¼: {menu_context}
MÃ¼ÅŸteri: {transcript}"""
```

#### 12. Menu Caching
**Problem:** Sending full menu every request wastes tokens.  
**Solution:** Cache menu per session (WebSocket connection).  
**Impact:** 20-30% token reduction.

```python
# Menu sent once at connection start, reused for all requests
menu_context = "\n".join([f"- {p.name}: {p.price}TL" for p in products])
```

---

### Connection Optimization

#### 13. HTTP Keep-Alive (connection pooling)
**Problem:** Each API call opens new connection.  
**Solution:** Reuse TCP connections with httpx pool.  
**Impact:** 100-200ms per request.

```python
# backend/core/fal_client_pool.py
class FalClientPool:
    _client = None
    
    @classmethod
    def get_client(cls):
        if cls._client is None:
            cls._client = httpx.Client(
                timeout=60,
                limits=httpx.Limits(max_keepalive_connections=5)
            )
        return cls._client
```

---

### Code-Level Optimization

#### 14. Non-Blocking Event Loop
**Problem:** CPU-bound tasks block async event loop.  
**Solution:** Run in thread pool with `asyncio.to_thread()`.  
**Impact:** Event loop stays responsive.

```python
# backend/services/stt.py
result = await asyncio.to_thread(
    fal_client.subscribe,  # CPU-bound API call
    self.model,
    arguments={...}
)
```

#### 15. Audio Trimming (100-200ms saved)
**Problem:** Silence at start/end wastes processing time.  
**Solution:** Smart RMS-based silence removal.  
**Impact:** Smaller audio, faster STT.

```javascript
// frontend/src/utils/AudioTrimmer.js
async trimSilence(audioBlob) {
  const {startIndex, endIndex} = this._findNonSilentRegion(channelData);
  const trimmedBuffer = audioBuffer.slice(startIndex, endIndex);
  return trimmedBlob;  // Typically 300-500ms shorter
}
```

---

### Performance Monitoring

All stages log timing:

```python
# backend/routers/voice_routes.py
start_time = time.time()
print(f"[START] Audio received: 00:00.000")

transcript = await stt_service.transcribe_stream(audio_data, start_time)
print(f"[STT done]: {time.time() - start_time:06.3f}s")

# ... LLM processing
print(f"[LLM first token]: {elapsed:06.3f}s")
print(f"[LLM complete]: {elapsed:06.3f}s")

# ... TTS streaming
print(f"[Audio playback start]: {elapsed:06.3f}s")
print(f"[COMPLETE] Total: {elapsed:06.3f}s")
```

**Target metrics:**
- STT: < 1.0s
- LLM first token: < 0.5s
- TTS first chunk: < 0.3s
- **Total perceived: < 2.2s** âœ…

---

## ğŸ’» Development

### Project Structure

```
fal-freya-garsonai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py              # JWT authentication
â”‚   â”‚   â”œâ”€â”€ config.py            # Settings (Pydantic)
â”‚   â”‚   â”œâ”€â”€ database.py          # SQLAlchemy setup
â”‚   â”‚   â””â”€â”€ fal_client_pool.py   # HTTP connection pooling
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ models.py            # SQLAlchemy ORM models
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ auth_routes.py       # /api/auth/*
â”‚   â”‚   â”œâ”€â”€ menu_routes.py       # /api/menu/*
â”‚   â”‚   â”œâ”€â”€ restaurant_routes.py # /api/restaurant/*
â”‚   â”‚   â””â”€â”€ voice_routes.py      # /ws/voice/* (WebSocket)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chunked_upload.py    # (Experimental) resumable uploads
â”‚   â”‚   â”œâ”€â”€ llm.py               # Gemini 2.5 Flash (OpenRouter)
â”‚   â”‚   â”œâ”€â”€ stt.py               # Freya STT (Whisper)
â”‚   â”‚   â”œâ”€â”€ tts.py               # Freya TTS (streaming)
â”‚   â”‚   â””â”€â”€ tts_warmer.py        # Background warmup task
â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ manager.py           # WebSocket connection manager
â”‚   â”œâ”€â”€ .env                     # Environment config (gitignored)
â”‚   â”œâ”€â”€ .env.example             # Template for .env
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry point
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ README.md                # (This file will replace it)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AIResponse.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Cart.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CartItem.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ LoginPage.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MenuNavbar.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ MenuProductCard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ OrderCard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ OrdersList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductCard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductForm.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductsList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StatusBadge.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TableCard.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TableForm.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TablesList.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Tabs.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptDisplay.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceButton.jsx
â”‚   â”‚   â”‚   â””â”€â”€ Waveform.jsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ ManagerDashboard.jsx  # Restaurant admin panel
â”‚   â”‚   â”‚   â”œâ”€â”€ Menu.jsx              # Customer menu view
â”‚   â”‚   â”‚   â””â”€â”€ VoiceAI.jsx           # Voice interface
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js                # API client (fetch wrapper)
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioCompressor.js    # Audio optimization
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioTrimmer.js       # Silence removal
â”‚   â”‚   â”‚   â”œâ”€â”€ SmartAudioPlayer.js   # (Deprecated) MP3 player
â”‚   â”‚   â”‚   â”œâ”€â”€ StreamingAudioPlayer.js  # PCM16 streaming player
â”‚   â”‚   â”‚   â””â”€â”€ VoiceActivityDetector.js # VAD (silence detection)
â”‚   â”‚   â”œâ”€â”€ App.jsx                   # Router setup
â”‚   â”‚   â”œâ”€â”€ index.css                 # TailwindCSS imports
â”‚   â”‚   â””â”€â”€ main.jsx                  # React entry point
â”‚   â”œâ”€â”€ .eslintrc.js
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                    # â† YOU ARE HERE
â”œâ”€â”€ setup.sh                     # Quick setup script
â””â”€â”€ start-optimized.sh           # Production start script
```

---

### Development Workflow

#### 1. Backend Development

```bash
cd backend

# Activate virtual environment
source venv/bin/activate

# Install new dependency
pip install package-name
pip freeze > requirements.txt

# Run with auto-reload
uvicorn main:app --reload --loop uvloop

# Run tests (if implemented)
pytest tests/
```

**Key Files to Edit:**
- `routers/voice_routes.py` - Voice pipeline logic
- `services/*.py` - AI service integrations
- `models/models.py` - Database schema changes

**Database Migration:**
```python
# SQLAlchemy auto-creates tables on startup
# For schema changes:
# 1. Edit models/models.py
# 2. Restart server (tables updated via Base.metadata.create_all)
# 
# For production, use Alembic:
# alembic revision --autogenerate -m "Add new column"
# alembic upgrade head
```

#### 2. Frontend Development

```bash
cd frontend

# Install new package
npm install package-name

# Run dev server (HMR enabled)
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

**Key Files to Edit:**
- `pages/VoiceAI.jsx` - Voice interface logic
- `utils/StreamingAudioPlayer.js` - Audio playback
- `components/*.jsx` - UI components

**Styling:**
- Uses TailwindCSS + DaisyUI
- Edit `index.css` for global styles
- Component styles are inline Tailwind classes

#### 3. Testing Voice Pipeline

**Step-by-step:**
1. Start backend: `uvicorn main:app --reload --loop uvloop`
2. Start frontend: `npm run dev`
3. Login to create restaurant
4. Create table â†’ Copy QR link
5. Open QR link in new tab
6. Click "Voice AI" button
7. Allow microphone permission
8. Speak: "Ä°ki pizza lÃ¼tfen"
9. Check console logs for timing metrics

**Expected console output:**
```
[Frontend]
ğŸ¤ Recording started
ğŸ“¤ Streaming chunk: 1234 bytes
ğŸ“¤ Streaming chunk: 1567 bytes
ğŸ¯ VAD: Auto-stopping due to silence (800ms)

[Backend]
ğŸ“¦ Chunk 1: 1234 bytes
ğŸ“¦ Chunk 2: 1567 bytes
[START] Processing 2 chunks (2801 bytes)
ğŸ¤ STT: Received 2801 bytes
[STT done]: 000.856s
ğŸ“ Transcript: Ä°ki pizza lÃ¼tfen
[LLM first token]: 001.234s
âš¡ Parallel TTS: Starting...
[Audio playback start]: 001.567s (parallel TTS first chunk)
[LLM complete]: 001.890s
[COMPLETE] Total pipeline: 002.123s âœ…
```

#### 4. Debugging Tips

**Backend errors:**
```bash
# Check logs
tail -f logs/uvicorn.log  # If logging to file

# Enable debug mode
# In backend/.env:
DEBUG=True

# Test STT directly
cd backend
python -c "
from services import STTService
import asyncio

async def test():
    stt = STTService()
    with open('test.webm', 'rb') as f:
        result = await stt.transcribe_stream(f.read(), 0)
    print(result)

asyncio.run(test())
"
```

**Frontend errors:**
```javascript
// Check WebSocket connection
ws.onopen = () => console.log("âœ… WebSocket connected");
ws.onerror = (err) => console.error("âŒ WebSocket error:", err);
ws.onclose = () => console.log("ğŸ”Œ WebSocket closed");

// Check audio capture
navigator.mediaDevices.getUserMedia({audio: true})
  .then(stream => console.log("âœ… Mic access granted", stream))
  .catch(err => console.error("âŒ Mic error:", err));

// Check audio compression
const audioBlob = new Blob([...], {type: 'audio/webm'});
const compressor = new AudioCompressor();
const compressed = await compressor.compressAudio(audioBlob);
console.log("Compression:", audioBlob.size, "â†’", compressed.size);
```

---

## ğŸš¢ Production Deployment

### Environment Setup

#### Backend (Python)

```bash
# Install production server
pip install uvicorn[standard] gunicorn

# Run with Gunicorn (multi-worker)
gunicorn main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --loop uvloop \
  --timeout 120 \
  --access-logfile - \
  --error-logfile -
```

**Systemd Service:**
```ini
# /etc/systemd/system/garsonai-backend.service
[Unit]
Description=GarsonAI Backend
After=network.target

[Service]
Type=notify
User=www-data
WorkingDirectory=/var/www/garsonai/backend
Environment="PATH=/var/www/garsonai/backend/venv/bin"
ExecStart=/var/www/garsonai/backend/venv/bin/gunicorn main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 127.0.0.1:8000 \
  --loop uvloop
Restart=always

[Install]
WantedBy=multi-user.target
```

#### Frontend (Vite)

```bash
# Build for production
cd frontend
npm run build

# Serve with nginx
# Output: frontend/dist/
```

**Nginx Configuration:**
```nginx
server {
    listen 80;
    server_name garsonai.example.com;

    # Frontend (static files)
    location / {
        root /var/www/garsonai/frontend/dist;
        try_files $uri $uri/ /index.html;
    }

    # Backend API
    location /api/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    # WebSocket
    location /ws/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_read_timeout 3600s;
        proxy_send_timeout 3600s;
    }

    # SSL (Let's Encrypt)
    listen 443 ssl;
    ssl_certificate /etc/letsencrypt/live/garsonai.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/garsonai.example.com/privkey.pem;
}
```

---

### Docker Deployment

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  db:
    image: postgres:14
    environment:
      POSTGRES_DB: garsonai
      POSTGRES_USER: garsonai
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always

  backend:
    build: ./backend
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --loop uvloop --ws websockets
    volumes:
      - ./backend:/app
    environment:
      DATABASE_URL: postgresql://garsonai:${DB_PASSWORD}@db:5432/garsonai
      FAL_KEY: ${FAL_KEY}
      OPENROUTER_API_KEY: ${OPENROUTER_API_KEY}
      SECRET_KEY: ${SECRET_KEY}
    depends_on:
      - db
    restart: always

  frontend:
    build: ./frontend
    ports:
      - "80:80"
      - "443:443"
    environment:
      VITE_API_URL: https://api.garsonai.example.com
      VITE_WS_URL: wss://api.garsonai.example.com
    depends_on:
      - backend
    restart: always

volumes:
  postgres_data:
```

**Backend Dockerfile:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--loop", "uvloop"]
```

**Frontend Dockerfile:**
```dockerfile
FROM node:18 AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

---

### Monitoring

#### Health Check Endpoints

```python
# backend/main.py
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "database": check_db_connection(),
            "fal_api": check_fal_connection(),
            "openrouter": check_openrouter_connection()
        }
    }
```

#### Logging

```python
# backend/main.py
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/garsonai.log'),
        logging.StreamHandler()
    ]
)
```

#### Metrics (Prometheus)

```python
# backend/main.py
from prometheus_client import Counter, Histogram

voice_requests = Counter('voice_requests_total', 'Total voice requests')
voice_latency = Histogram('voice_latency_seconds', 'Voice pipeline latency')

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)
```

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. Microphone not accessible

**Error:** `DOMException: Permission denied`

**Solution:**
- Check browser permissions (chrome://settings/content/microphone)
- Use HTTPS in production (getUserMedia requires secure context)
- On localhost, HTTP is allowed

---

#### 2. WebSocket connection fails

**Error:** `WebSocket connection failed`

**Checks:**
```javascript
// Ensure backend is running
curl http://localhost:8000/health

// Test WebSocket endpoint
wscat -c ws://localhost:8000/ws/voice/test-token

// Check CORS (if backend on different domain)
// backend/main.py should have:
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # Add your frontend URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

#### 3. High latency (> 3s)

**Diagnostics:**
```bash
# Check backend logs for timing
grep "\[COMPLETE\]" logs/uvicorn.log

# Check if uvloop is active
ps aux | grep uvicorn
# Should show: --loop uvloop

# Verify warmup tasks are running
grep "TTS warmer" logs/uvicorn.log
# Should show: "ğŸš€ Starting TTS warmer..."
```

**If still slow:**
- Check network latency to fal.ai (EU region preferred)
- Verify audio is compressed (check size in network tab)
- Test STT/LLM/TTS services individually
- Check database query performance (add indexes)

---

#### 4. Audio playback choppy/stuttering

**Causes:**
- Incorrect PCM conversion (check Float32 normalization)
- Sample rate mismatch (ensure 16kHz throughout)
- AudioContext suspended (user gesture required)

**Solution:**
```javascript
// frontend/src/utils/StreamingAudioPlayer.js

// Ensure sample rate matches
const audioContext = new AudioContext({sampleRate: 16000});

// Resume context on user interaction
audioContext.resume();

// Check PCM conversion
const normalized = sample / 32768.0;  // Int16 â†’ Float32
```

---

#### 5. STT returns empty string

**Checks:**
```bash
# Verify audio format
file audio.webm
# Should show: WebM audio

# Test fal.ai API directly
curl -X POST "https://queue.fal.run/freya-mypsdi253hbk/freya-stt/generate" \
  -H "Authorization: Key YOUR_FAL_KEY" \
  -d '{"audio_url": "https://example.com/audio.webm", "language": "tr"}'

# Check audio duration (> 0.5s required)
ffprobe -i audio.webm -show_entries format=duration
```

---

#### 6. LLM returns malformed JSON

**Debug:**
```python
# backend/services/llm.py

# Log raw LLM output
print(f"Raw LLM response: {full_response}")

# Add JSON validation
try:
    parsed = json.loads(full_response)
except JSONDecodeError as e:
    print(f"JSON parse error: {e}")
    print(f"Failed text: {full_response}")
```

**Solution:** Improve prompt constraints
```python
prompt = """Return ONLY valid JSON. Example:
{"spoken_response":"Tabii, iki pizza ekliyorum!","intent":"add","product_name":"Pizza","quantity":2}
No markdown, no explanation."""
```

---

#### 7. Database connection errors

**Error:** `sqlalchemy.exc.OperationalError: could not connect to server`

**Checks:**
```bash
# Verify PostgreSQL is running
sudo systemctl status postgresql

# Test connection
psql -U garsonai -d garsonai -h localhost

# Check DATABASE_URL format
# Correct: postgresql://user:pass@host:5432/db
# Wrong: postgres://... (use postgresql://)
```

---

#### 8. High memory usage

**Cause:** WebSocket connections not cleaned up

**Solution:**
```python
# backend/websocket/manager.py

def disconnect(self, websocket: WebSocket, table_id: str):
    if table_id in self.active_connections:
        self.active_connections[table_id].discard(websocket)
        # Clean up empty sets
        if not self.active_connections[table_id]:
            del self.active_connections[table_id]
```

---

#### 9. VAD too sensitive (stops mid-sentence)

**Adjust threshold:**
```javascript
// frontend/src/utils/VoiceActivityDetector.js

// Less sensitive (allow quieter speech)
this.silenceThreshold = 0.005;  // Was 0.01

// Longer silence required
this.silenceDuration = 1200;  // Was 800ms
```

---

#### 10. TTS voice quality poor

**Improve:**
```python
# backend/services/tts.py

arguments = {
    "input": text,
    "voice": "zeynep",  # Turkish female (best quality)
    "speed": 1.0,       # Normal speed (was 1.15x)
    "format": "pcm16",  # Highest quality
    "sample_rate": 24000  # Upgrade from 16kHz
}

# Note: Frontend StreamingAudioPlayer must match sample_rate
```

---

## ğŸ“„ License

MIT License - See LICENSE file for details.

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“ Support

For issues or questions:
- GitHub Issues: [Create an issue]
- Email: support@garsonai.example.com
- Discord: [Join our community]

---

## ğŸ™ Acknowledgments

- **fal.ai** - STT/TTS infrastructure (Freya models)
- **OpenRouter** - LLM API gateway (Gemini access)
- **FastAPI** - Modern Python web framework
- **React** - Frontend UI library
- **TailwindCSS + DaisyUI** - Beautiful UI components

---

## ğŸ“ˆ Roadmap

### v1.1 (Planned)
- [ ] Multi-language support (English, Arabic)
- [ ] Voice authentication per table
- [ ] Order modification via voice
- [ ] Payment integration (Stripe/PayU)
- [ ] Analytics dashboard

### v1.2 (Future)
- [ ] Offline mode (service worker)
- [ ] Native mobile apps (React Native)
- [ ] Kitchen display system
- [ ] Waiter call functionality
- [ ] Multi-restaurant chains support

---

**Built with â¤ï¸ by GarsonAI Team**

*Making restaurant ordering seamless, one voice at a time.* ğŸ™ï¸ğŸ•
